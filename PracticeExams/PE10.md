## Introduction
This lab provides practice scenarios to help prepare you for the Certified Kubernetes Application Developer (CKAD) exam. You will be presented with tasks to complete, as well as server(s) and/or an existing Kubernetes cluster to complete them in. You will need to use your knowledge of Kubernetes to successfully complete the provided tasks, much like you would on the real CKAD exam. Good luck!

## Lab Environment
Use the provided environment to complete the tasks detailed in the learning objectives.

You can access all components of the cluster from the CLI server. The control plane server is k8s-control, and the worker is k8s-worker1. If you need to log in to the control plane server, for example, just use ssh k8s-control from the CLI server.

You can also use kubectl from the CLI server, control plane node, or worker to interact with the cluster. In order to use kubectl from the CLI server, you will need to select the acgk8s cluster to interact with, like so: kubectl config use-context acgk8s.

kubectl is aliased to k, and Kubernetes autocompletion is enabled. You can use the k alias like so: k get pods.

This lab includes a verification script to help you determine whether you have completed the objectives successfully. You can run the verification script with /home/cloud_user/verify.sh.

## Solution
Log in to the server using the credentials provided:
```shell
ssh cloud_user@<PUBLIC_IP_ADDRESS>
```
Switch to the acgk8s cluster context:
```shell
kubectl config use-context acgk8s
```
Create a Blue/Green Setup for an Existing Deployment
Make a copy of the existing Deployment manifest:
```shell
cp bluegreen/web-frontend.yml bluegreen/web-frontend-green.yml
```
Edit the new manifest to configure the green Deployment:

Note: When copying and pasting code into Vim from the lab guide, first enter :set paste (and then i to enter insert mode) to avoid adding unnecessary spaces and hashes. To save and quit the file, press Escape followed by :wq. To exit the file without saving, press Escape followed by :q!.
```shell
vi bluegreen/web-frontend-green.yml
```
Change the Deployment name from web-frontend to web-frontend-green:
```shell
metadata:
  name: web-frontend-green
```
Change both of the env labels from main to green in the selector and the Pod template sections:
```shell
  selector:
    matchLabels:
      app: web-frontend
      env: green
  template:
    metadata:
      labels:
        app: web-frontend
        env: green
```
Type ESC followed by :wq to save your changes.

Create the green Deployment with kubectl apply:
```shell
kubectl apply -f bluegreen/web-frontend-green.yml
```
Check the Pods' status:
```shell
kubectl get pods -n bluegreen -o wide
```
Copy the IP address of one of the green Pods to use in one of the next steps.

Log in to the control plane node:
```shell
ssh k8s-control
```
Test the green Pod using the IP address you copied before:
```shell
curl <green_Pod_IP_address>
```
You should receive a response listing the Pod's labels.

Return to the CLI server:
```shell
exit
```
Edit the Service to point it to the new green Deployment's Pods:
```shell
kubectl edit svc web-frontend-svc -n bluegreen
```
Scroll down, and change the value of the env label in the selector from main to green:
```shell
  selector:
    app: web-frontend
    env: green
```
Type ESC followed by :wq to save your changes.

Test the Service a few times:
```shell
curl k8s-control:30081
```
You should get responses only from the green Pod(s). This shows that the Service is pointing only to the green Deployment.

Run the verification script to ensure you completed the objective:
```shell
~/verify.sh
```
Create a Canary Setup for an Existing Deployment
Make a copy of the existing Deployment manifest:
```shell
cp canary/auth.yml canary/auth-canary.yml
```
Edit the new manifest to configure the canary Deployment:
```shell
vi canary/auth-canary.yml
```
Change the Deployment name from auth to auth-canary:
```shell
metadata:
  name: auth-canary
```
Change the number of replicas from 2 to 1:
```shell
spec:
  replicas: 1
```
Change the env label from main to canary in both the selector and the Pod template:
```shell
  selector:
    matchLabels:
      app: auth
      env: canary
  template:
    metadata:
      labels:
        app: auth
        env: canary
```
Type ESC followed by :wq to save your changes.

Create the canary Deployment with kubectl apply:
```shell
kubectl apply -f canary/auth-canary.yml
```
Check the Pods' status:
```shell
kubectl get pods -n canary
```
You should see the 2 main Pods and the 1 replica from the canary Deployment.

Edit the Service to point it to the Pods from both Deployments:
```shell
kubectl edit svc auth-svc -n canary
```
Scroll down to the selector. Remove the env label line from the selector, leaving only the app label:
```shell
  selector:
    app: auth
```
Type ESC followed by :wq to save your changes.

Edit the main Deployment to set its replica count appropriately:
```shell
vi canary/auth.yml
```
Change the replica count from 2 to 3:
```shell
spec:
  replicas: 3
```
Type ESC followed by :wq to save your changes.

Apply the changes with kubectl apply:
```shell
kubectl apply -f canary/auth.yml
```
Check the Pods in the canary Namespace:
```shell
kubectl get pods -n canary
```
You should see 3 replicas in the main Deployment and 1 replica in the canary Deployment.

Test the Service a few times:
```shell
curl k8s-control:30082
```
You should get responses from both the main and canary Pods.

Run the verification script to ensure you completed the objective:
```shell
~/verify.sh
```
